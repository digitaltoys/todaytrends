# 데이터 수집 모듈 설계

## 1. 각 SNS 플랫폼별 API 연동 및 스크래핑 로직 구분 설계

### 1.1. X (구 트위터)

*   **API 활용 방안:**
    *   X API v2 (Twitter API v2) 사용.
    *   주요 엔드포인트:
        *   `GET /2/tweets/search/recent`: 최근 7일 내 트윗 검색 (키워드, 해시태그, 사용자 등).
        *   `GET /2/users/:id/tweets`: 특정 사용자 트윗 조회.
        *   `GET /2/tweets/:id`: 특정 트윗 상세 정보 조회.
    *   인증 방식: OAuth 2.0 Bearer Token (App-only) 또는 OAuth 1.0a (User context). 프로젝트 성격상 App-only 방식이 적합해 보임.
    *   요청/응답 데이터 형식: JSON.
    *   무료 티어: 월 50만 트윗 수집 가능 (프로젝트 초기 단계에 충분할 것으로 예상).
*   **스크래핑 활용 방안:**
    *   API 제한 초과 시 또는 API에서 제공하지 않는 정보 (예: 특정 UI 요소, 비공식 트렌드 정보 등) 수집 시 보조적으로 활용.
    *   주의사항: X API 사용 정책 및 속도 제한(Rate Limit)을 준수해야 합니다.
*   **로직 흐름 (API 우선):**
    1.  X API를 통해 데이터 수집을 시도합니다.
    2.  API 호출이 성공하면 수집된 데이터를 정규화 단계로 전달합니다.
    3.  API 호출 실패 또는 할당량 초과 시, 오류를 로깅하고 정해진 정책에 따라 재시도하거나 관리자에게 알립니다. (스크래핑은 향후 고려)

### 1.2. 인스타그램

*   **API 활용 방안:**
    *   Instagram Graph API 사용을 목표로 합니다. (Facebook Business 계정 및 앱 필요, 승인 절차 확인 필요)
    *   주요 엔드포인트:
        *   `GET /{user-id}/media`: 특정 사용자 미디어 조회.
        *   `GET /{ig-hashtag-id}/recent_media` 또는 `GET /{ig-hashtag-id}/top_media`: 해시태그 기반 미디어 검색.
    *   인증 방식: OAuth 2.0.
    *   요청/응답 데이터 형식: JSON.
    *   제한 사항: API 접근 권한 획득 절차가 복잡하고, 개인 계정 데이터 접근에 한계가 있을 수 있습니다. 공개 콘텐츠 위주 수집을 우선 고려합니다. 해시태그 검색 기능의 제한 사항(예: 최근 24시간 내 미디어만 가능 등)을 확인해야 합니다.
    *   주의사항: Instagram API 사용 정책 및 속도 제한을 준수해야 합니다.
*   **로직 흐름 (API 우선):**
    1.  Instagram Graph API를 통해 데이터 수집을 시도합니다.
    2.  API 호출이 성공하면 수집된 데이터를 정규화 단계로 전달합니다.
    3.  API 호출 실패, 승인 문제 또는 원하는 데이터를 얻기 어려울 경우 오류를 로깅하고 정해진 정책에 따라 처리합니다. (스크래핑은 향후 고려)

### 1.3. 틱톡

*   **API 활용 방안:**
    *   TikTok Developer API 사용을 목표로 합니다. (공식 API 신청 및 승인 절차 필요)
    *   공식 API 사용 가능 시 주요 엔드포인트: 트렌드, 키워드 검색, 사용자 게시물 등.
    *   인증 방식: OAuth 2.0.
    *   요청/응답 데이터 형식: JSON.
    *   주의사항: TikTok API 사용 정책, 승인 조건 및 속도 제한을 준수해야 합니다. 비공식 API나 라이브러리는 안정성 문제로 사용을 지양합니다.
*   **로직 흐름 (API 우선):**
    1.  TikTok Developer API를 통해 데이터 수집을 시도합니다.
    2.  API 호출이 성공하면 수집된 데이터를 정규화 단계로 전달합니다.
    3.  API 접근이 어렵거나 승인되지 않을 경우, 또는 API 호출 실패 시 오류를 로깅하고 대안을 검토합니다. (스크래핑은 향후 고려)

### 1.4. 유튜브 쇼츠

*   **API 활용 방안:**
    *   YouTube Data API v3 사용.
    *   주요 엔드포인트:
        *   `search.list`: `q` 파라미터로 키워드 검색, `type=video`, `videoDuration=short` (또는 `videoDefinition` 등으로 필터링) 등을 활용하여 쇼츠 영상 검색.
        *   `videos.list`: 특정 비디오 ID로 상세 정보 조회.
        *   `channels.list`, `playlistItems.list`: 특정 채널의 쇼츠 영상 목록 수집.
    *   인증 방식: API Key (간단한 조회) 또는 OAuth 2.0 (사용자 데이터 접근 시).
    *   요청/응답 데이터 형식: JSON.
    *   할당량: 일일 할당량 제한이 있으므로 효율적인 API 사용 계획이 필요합니다.
    *   주의사항: YouTube API 사용 정책 및 속도 제한을 준수해야 합니다.
*   **로직 흐름 (API 우선):**
    1.  YouTube Data API를 통해 쇼츠 데이터 수집을 시도합니다.
    2.  API 호출이 성공하면 수집된 데이터를 정규화 단계로 전달합니다.
    3.  API 호출 실패 또는 할당량 초과 시 오류를 로깅하고 정해진 정책에 따라 재시도하거나 알립니다. (스크래핑은 향후 고려)

### 1.5. 스레드 (Threads)

*   **API 활용 방안:**
    *   현재 (문서 작성 시점 기준) 공식 Threads API는 제공되지 않습니다. 향후 Meta에서 API를 제공할 가능성을 주시합니다.
    *   비공식 API나 라이브러리는 안정성 및 지속성 문제로 사용을 지양합니다.
*   **로직 흐름 (API 부재로 인한 대기):**
    1.  공식 API 제공 여부를 주기적으로 확인합니다.
    2.  공식 API가 제공되면, 해당 API 명세를 분석하여 연동 계획을 수립합니다.
    3.  현재로서는 Threads 데이터 수집은 공식 API가 나올 때까지 보류하거나, 매우 제한적인 방식(예: RSS 피드가 있다면 활용)만 고려합니다. (스크래핑은 향후 공식 API 지원이 없을 경우 최후의 수단으로 고려)

---

## 2. 데이터 정규화 방안 설계

다양한 SNS 플랫폼에서 수집되는 데이터는 각기 다른 구조와 필드명을 가질 수 있습니다. 일관된 데이터 처리 및 분석을 위해 수집된 데이터를 표준화된 공통 형식으로 변환하는 과정이 필요합니다.

### 2.1. 공통 데이터 모델 정의 (예시)

다음은 각기 다른 플랫폼에서 수집될 수 있는 정보들을 통합적으로 관리하기 위한 공통 데이터 모델의 예시입니다. 실제 구현 시에는 요구사항에 따라 필드가 추가되거나 수정될 수 있습니다.

```json
{
  "id": "플랫폼별_고유_게시물_ID", // 예: "twitter_1234567890"
  "platform": "수집된_플랫폼_명칭", // "X", "Instagram", "TikTok", "YouTubeShorts", "Threads"
  "url": "원본_게시물_URL",
  "text_content": "게시물_본문_내용",
  "author_id": "작성자_고유_ID",
  "author_name": "작성자_표시_이름",
  "author_username": "작성자_사용자명_또는_계정명",
  "author_profile_image_url": "작성자_프로필_이미지_URL",
  "created_at": "YYYY-MM-DDTHH:mm:ssZ", // ISO 8601 형식 (UTC)
  "collected_at": "YYYY-MM-DDTHH:mm:ssZ", // 데이터 수집 시간 (UTC)
  "media": [ // 미디어 정보 (이미지, 비디오 등)
    {
      "type": "image_or_video", // "image", "video"
      "url": "미디어_URL",
      "thumbnail_url": "썸네일_이미지_URL (선택적)"
    }
  ],
  "hashtags": ["해시태그1", "해시태그2"],
  "mentions": ["언급된_사용자1", "언급된_사용자2"], // 사용자명 또는 ID
  "engagement_metrics": { // 참여 지표
    "likes_count": 123,
    "comments_count": 45,
    "shares_count": 67, // 또는 리트윗, 다시게시 등 플랫폼별 용어
    "views_count": 1000 // 조회수 (해당되는 경우)
  },
  "location": { // 위치 정보 (사용 가능한 경우)
    "name": "장소_이름",
    "coordinates": {
      "latitude": 37.12345,
      "longitude": 127.12345
    }
  },
  "language": "게시물_언어_코드", // 예: "ko", "en"
  "is_sensitive_content": false, // 민감한 콘텐츠 여부
  "raw_data": { ... } // 플랫폼별 원본 데이터 (선택적, 디버깅 및 추후 분석용)
}
```

### 2.2. 필드별 정규화 규칙 (예시)

*   **`id`**: 각 플랫폼에서 제공하는 고유 ID 앞에 플랫폼 명칭을 접두사로 붙여 전체 시스템에서 유일하도록 합니다. (예: `twitter_{tweet_id}`, `instagram_{media_id}`)
*   **`platform`**: 일관된 플랫폼 식별자 문자열을 사용합니다. (예: 'X', 'Instagram', 'TikTok', 'YouTubeShorts', 'Threads')
*   **`created_at`**: 모든 날짜/시간 정보는 ISO 8601 형식의 UTC로 통일합니다. 플랫폼에서 제공하는 시간 정보가 타임존을 포함하지 않거나 로컬 시간일 경우 UTC로 변환하는 로직이 필요합니다.
*   **`text_content`**: HTML 태그 제거, URL 축약 해제, 이모지 처리 등 기본적인 텍스트 정제 과정을 포함할 수 있습니다.
*   **`media`**: 이미지, 비디오 URL을 추출하고, 가능한 경우 썸네일 URL도 함께 저장합니다. 미디어 유형을 명시합니다.
*   **`hashtags`**: `#` 기호를 제외하고 텍스트만 추출하여 배열로 저장합니다.
*   **`engagement_metrics`**: 각 플랫폼별 용어(예: "favorites", "retweets")를 공통 용어(예: "likes_count", "shares_count")로 매핑합니다. 값이 제공되지 않는 경우 `null` 또는 `0`으로 처리합니다.

### 2.3. 데이터 정규화 프로세스

1.  **데이터 수집**: 각 플랫폼별 수집기(API 클라이언트 또는 스크래퍼)가 데이터를 가져옵니다.
2.  **어댑터(Adapter) 구현**: 각 플랫폼별로 수집된 원본 데이터를 위에서 정의한 공통 데이터 모델로 변환하는 어댑터 모듈을 구현합니다.
    *   어댑터는 플랫폼별 데이터 구조의 차이를 흡수하고, 필드 매핑, 데이터 타입 변환, 값 정규화 등을 수행합니다.
3.  **변환된 데이터 활용**: 정규화된 데이터는 후속 처리 단계(분석, 저장 등)에서 일관된 방식으로 사용될 수 있습니다.

이러한 정규화 과정을 통해 다양한 소스에서 오는 데이터를 효과적으로 통합하고 관리할 수 있으며, 시스템의 유연성과 확장성을 높일 수 있습니다.

---
